{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605ba607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1182e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "files = os.listdir()\n",
    "# for i in files:\n",
    "#     if i.endswith('.xlsx'):\n",
    "#         print(i)\n",
    "import json\n",
    "filepath = 'Flow chart english.xlsx'\n",
    "os.path.exists(filepath)\n",
    "\n",
    "# Load Excel (adjust path and sheet name as needed)\n",
    "df = pd.read_excel(filepath, header=9)\n",
    "columns_to_drop = ['Process Symbols','Improve content', 'Inspection Problem Description','Improvement goals.1', \n",
    "                   'Current Level', 'Improvement goals.2', 'Unnamed: 25', 'Unnamed: 26', 'Expected', 'actual', 'BU', 'Manufacturing CoE-IE',\n",
    "                   'Number of operators', 'Average working hours at workstations (Sec.)','Unnamed: 34','Unnamed: 35',\n",
    "                   'Assignment content.1','Single time','Number of jobs','Total working hours', ' Saturation']\n",
    "df = df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "print(len(df))\n",
    "# df.head()\n",
    "# print(df.to_string(index=False, max_cols=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c84ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'name': 'Product Number', \n",
    "                        'Serial number': 'Workstation number', \n",
    "                        'name.1': 'Workstation name',\n",
    "                        'Serial number.1': 'Serial number',\n",
    "                        'Unnamed: 10': 'Number of operators',\n",
    "                        'Unnamed: 11': 'Average Working hours (Sec.)',\n",
    "                        'Unnamed: 12': 'Current manual labor saturation',\n",
    "                        'Process': 'Value Judgment Process',\n",
    "                        'unit': 'Value Judgment unit',\n",
    "                        })\n",
    "print(df.to_string(index=False, max_cols=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1189502b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa99d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Workstation number'] = df['Workstation number'].fillna(method='ffill')\n",
    "df['Workstation name'] = df['Workstation name'].fillna(method='ffill')\n",
    "df['Machine (Sec.)'] = df['Machine (Sec.)'].fillna(0)\n",
    "df['Number of products'] = df['Number of products'].fillna(method='ffill')\n",
    "df['Working hours (Sec.)'] = df['Working hours (Sec.)'].fillna(method='ffill')\n",
    "df['Number of operators'] = df['Number of operators'].fillna(method='ffill')\n",
    "df['Average Working hours (Sec.)'] = df['Average Working hours (Sec.)'].fillna(method='ffill')\n",
    "df['Current manual labor saturation'] = df['Current manual labor saturation'].fillna(method='ffill')\n",
    "df['Value Judgment Process'] = df['Value Judgment Process'].fillna(method='ffill')\n",
    "df['ECRS'] = df['ECRS'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eee6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_number = '3S6A013-00518-7F'\n",
    "edition = 'B'\n",
    "updated  = 263822\n",
    "approved_by = 'approved by'\n",
    "reviewer = 'reviewed by'\n",
    "prepared_by = 'prepared by'\n",
    "responsible_person = 'responsible person'\n",
    "\n",
    "# Apply header metadata to all rows\n",
    "df[\"Product Number\"] = product_number\n",
    "df[\"Edition\"] = edition\n",
    "df[\"Updated\"] = updated\n",
    "df[\"Approved by\"] = approved_by\n",
    "df[\"Reviewer\"] = reviewer\n",
    "df[\"Prepared by\"] = prepared_by\n",
    "df[\"Responsible Person\"] = responsible_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850ba7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Serial number'], inplace=True)\n",
    "print(df.to_string(index=False, max_cols=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11131c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ECRS'] = df['ECRS'].fillna('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8d7714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "mapping_action_item_classification = {'→': 'Transport', '○': 'Operation', '□': 'Inspect'}\n",
    "mapping_current_action_level = {'M1': 'Manual', 'M2': 'Semi automation', 'M3': 'Automation', 'M4': 'Advanced automation'}\n",
    "df['Action Item Classification'] = df['Action Item Classification'].replace(mapping_action_item_classification)\n",
    "df['Current Action Level'] = df['Current Action Level'].replace(mapping_current_action_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Workstation number'] = df['Workstation number'].astype('Int64')\n",
    "df['Serial number'] = df['Serial number'].astype('Int64')\n",
    "df['Number of products'] = df['Number of products'].astype('Int64')\n",
    "df['Number of operators'] = df['Number of operators'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403cc13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(len(df)).to_string(index=False, max_cols=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e725fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize list for documents\n",
    "# documents = []\n",
    "\n",
    "# # Group by Segment\n",
    "# for segment in df[\"Workstation number\"].unique():\n",
    "#     segment_df = df[df[\"Workstation number\"] == segment].copy()\n",
    "    \n",
    "#     # Extract process-level data\n",
    "#     workstation_number = segment_df[\"Workstation number\"].iloc[0]\n",
    "#     workstation_name = segment_df[\"Workstation name\"].iloc[0]\n",
    "#     number_of_products = segment_df[\"Number of products\"].iloc[0]\n",
    "#     working_hours_sec = segment_df[\"Working hours (Sec.)\"].iloc[0]\n",
    "#     number_of_operators = segment_df[\"Number of operators\"].iloc[0]\n",
    "#     average_working_hours_sec = segment_df[\"Average Working hours (Sec.)\"].iloc[0]\n",
    "#     current_manual_labor_saturation = segment_df[\"Current manual labor saturation\"].iloc[0]\n",
    "#     value_judgment_process = segment_df[\"Value Judgment Process\"].iloc[0]\n",
    "\n",
    "#     # Extract operations\n",
    "#     operations = []\n",
    "#     for _, row in segment_df.iterrows():\n",
    "#         operations.append({\n",
    "#             \"serial_number\": row[\"Serial number\"],\n",
    "#             \"description\": row[\"Assignment content\"],\n",
    "#             \"manual_sec\": row[\"Manual (Sec.)\"],\n",
    "#             \"machine_sec\": row[\"Machine (Sec.)\"],\n",
    "#             \"value_judgment_unit\": row[\"Value Judgment unit\"],\n",
    "#             \"action_item_classification\": row[\"Action Item Classification\"],\n",
    "#             \"current_action_level\": row[\"Current Action Level\"]\n",
    "#         })\n",
    "#         print(row[\"Current Action Level\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2479b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = []\n",
    "# doc_ids = []\n",
    "# metadatas = []\n",
    "# for i, doc in enumerate(documents):\n",
    "#     # Workstation document\n",
    "#     workstation_text = \"; \".join([\n",
    "#         f\"Workstation Number: {doc['Workstation number']}\",\n",
    "#         f\"Workstation Name: {doc['Workstation name']}\",\n",
    "#         f\"Number of Products: {doc['Number of products']}\",\n",
    "#         f\"Working hours (Sec.): {doc['Working hours (Sec.)']}\",\n",
    "#         f\"Number of Operators: {doc['Number of operators']}\",\n",
    "#         f\"Cycle Time (Sec.): {doc['Cycle Time (Sec.)']}\",\n",
    "#         f\"Job saturation (%): {doc['Job saturation (%)']}\",\n",
    "#         f\"Value Judgment Process: {doc['Value Judgment Process']}\",\n",
    "#         f\"Improvement Goals: {doc['improvement items']['goals'] if doc['improvement items']['goals'] != '/' else 'No improvements listed'}\"\n",
    "#     ])\n",
    "#     texts.append(workstation_text)\n",
    "#     doc_ids.append(f\"ws_{i}\")\n",
    "#     metadatas.append({\n",
    "#         \"product_number\": doc[\"product_number\"],\n",
    "#         \"workstation_number\": str(doc[\"Workstation number\"]),\n",
    "#         \"workstation_name\": doc[\"Workstation name\"],\n",
    "#         \"type\": \"workstation\"\n",
    "#     })\n",
    "    \n",
    "#     # Operation documents\n",
    "#     for j, op in enumerate(doc[\"operations\"]):\n",
    "#         op_text = \"; \".join([\n",
    "#             f\"Workstation Number: {doc['Workstation number']}\",\n",
    "#             f\"Workstation Name: {doc['Workstation name']}\",\n",
    "#             f\"Serial Number: {op['serial_number']}\",\n",
    "#             f\"Description: {op['description']}\",\n",
    "#             f\"Manual (sec): {op['manual_sec']}sec\",\n",
    "#             f\"Machine (sec): {op['machine_sec']}sec\",\n",
    "#             f\"Value Judgment Unit: {op['value_judgment_unit']}\",\n",
    "#             f\"Action Item Classification: {op['action_item_classification']}\",\n",
    "#             f\"Current Action Level: {op['current_action_level']}\"\n",
    "#         ])\n",
    "#         texts.append(op_text)\n",
    "#         doc_ids.append(f\"op_{i}_{j}\")\n",
    "#         metadatas.append({\n",
    "#             \"product_number\": doc[\"product_number\"],\n",
    "#             \"workstation_number\": str(doc[\"Workstation number\"]),\n",
    "#             \"workstation_name\": doc[\"Workstation name\"],\n",
    "#             \"serial_number\": str(op[\"serial_number\"]),\n",
    "#             \"type\": \"operation\"\n",
    "#         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(texts))\n",
    "print(len(doc_ids))\n",
    "print(len(metadatas))\n",
    "doc_ids\n",
    "texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422af637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list for documents\n",
    "documents = []\n",
    "\n",
    "# Group by Segment\n",
    "for segment in df[\"Workstation number\"].unique():\n",
    "    segment_df = df[df[\"Workstation number\"] == segment].copy()\n",
    "    \n",
    "    # Extract workstation level data\n",
    "    workstation_number = segment_df[\"Workstation number\"].iloc[0]\n",
    "    workstation_name = segment_df[\"Workstation name\"].iloc[0]\n",
    "    number_of_products = segment_df[\"Number of products\"].iloc[0]\n",
    "    working_hours_sec = segment_df[\"Working hours (Sec.)\"].iloc[0]\n",
    "    number_of_operators = segment_df[\"Number of operators\"].iloc[0]\n",
    "    average_working_hours_sec = segment_df[\"Average Working hours (Sec.)\"].iloc[0]\n",
    "    current_manual_labor_saturation = segment_df[\"Current manual labor saturation\"].iloc[0]\n",
    "    value_judgment_process = segment_df[\"Value Judgment Process\"].iloc[0]\n",
    "\n",
    "    # Extract operation level data\n",
    "    operations = []\n",
    "    for _, row in segment_df.iterrows():\n",
    "        operations.append({\n",
    "            \"serial_number\": row[\"Serial number\"],\n",
    "            \"description\": row[\"Assignment content\"],\n",
    "            \"manual_sec\": row[\"Manual (Sec.)\"],\n",
    "            \"machine_sec\": row[\"Machine (Sec.)\"],\n",
    "            \"value_judgment_unit\": row[\"Value Judgment unit\"],\n",
    "            \"action_item_classification\": row[\"Action Item Classification\"],\n",
    "            \"current_action_level\": row[\"Current Action Level\"]\n",
    "        })\n",
    "        \n",
    "    # Extract improvements\n",
    "    improvements = {\n",
    "        \"problem_description\": segment_df[\"Problem Description\"].iloc[0],\n",
    "        \"goals\": segment_df[\"Improvement goals\"].iloc[0],\n",
    "        \"ecrs\": segment_df[\"ECRS\"].iloc[0],\n",
    "    }\n",
    "    \n",
    "    # Metadata\n",
    "    metadata = {\n",
    "        \"edition\": segment_df[\"Edition\"].iloc[0],\n",
    "        \"updated\": segment_df[\"Updated\"].iloc[0],\n",
    "        \"approved_by\": segment_df[\"Approved by\"].iloc[0],\n",
    "        \"reviewer\": segment_df[\"Reviewer\"].iloc[0],\n",
    "        \"prepared_by\": segment_df[\"Prepared by\"].iloc[0],\n",
    "        \"responsible_person\": segment_df[\"Responsible Person\"].iloc[0]\n",
    "    }\n",
    "\n",
    "\n",
    "# Create document\n",
    "    document = {\n",
    "        \"product_number\": segment_df[\"Product Number\"].iloc[0],\n",
    "        \"Workstation number\": workstation_number,\n",
    "        \"Workstation name\": workstation_name,\n",
    "        \"Number of products\": number_of_products,\n",
    "        \"Working hours (Sec.)\": working_hours_sec,\n",
    "        \"Number of operators\": number_of_operators,\n",
    "        \"Cycle Time (Sec.)\": average_working_hours_sec,\n",
    "        \"Job saturation (%)\": current_manual_labor_saturation,\n",
    "        \"Value Judgment Process\": value_judgment_process,\n",
    "        \"operations\": operations,\n",
    "        \"improvement items\": improvements,\n",
    "        \"metadata\": metadata\n",
    "    }\n",
    "    documents.append(document)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad29a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a825cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data in JSON format\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()  # Convert NumPy arrays to lists\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(elem) for elem in obj]\n",
    "    return obj\n",
    "\n",
    "# Assuming 'documents' is your data structure\n",
    "serializable_documents = convert_to_serializable(documents)\n",
    "\n",
    "with open(\"structured_data_no_metrics.json\", \"w\") as f:\n",
    "    json.dump(serializable_documents, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f4430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"structured_data_no_metrics.json\", \"r\") as f:\n",
    "    loaded_documents = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8523d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3db987",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "doc_ids = []\n",
    "metadatas = []\n",
    "for i, doc in enumerate(loaded_documents):\n",
    "    # Combine fields into a single text string\n",
    "    workstation_text = \", \".join([\n",
    "        f\"Workstation Number: {doc['Workstation number']}, \"\n",
    "        f\"Workstation Name: {doc['Workstation name']}, \"\n",
    "        f\"Number of Products: {doc['Number of products']}, \"\n",
    "        f\"Working hours (Sec.): {doc['Working hours (Sec.)']}, \"\n",
    "        f\"Number of Operators: {doc['Number of operators']}, \"\n",
    "        f\"Cycle Time (Sec.): {doc['Cycle Time (Sec.)']}, \"\n",
    "        f\"Job saturation (%): {doc['Job saturation (%)']}, \"\n",
    "        f\"Value Judgment Process: {doc['Value Judgment Process']}, \"])\n",
    "    \n",
    "    ops_text = \", \".join([\n",
    "        f\"Serial Number: {op['serial_number']}, \" \n",
    "        f\"Description: {op['description']}, \" \n",
    "        f\"Manual (sec): {op['manual_sec']}sec, \" \n",
    "        f\"Machine (sec): {op['machine_sec']}sec, \" \n",
    "        f\"Value Judgment Unit: {op['value_judgment_unit']}, \" \n",
    "        f\"Action Item Classification: {op['action_item_classification']}, \" \n",
    "        f\"Current Action Level: {op['current_action_level']}\"\n",
    "        for op in doc[\"operations\"]])\n",
    "    text = f\"Workstation: {workstation_text}\\nOperations: {ops_text}\\nImprovements: {doc['improvement items']['goals'] if doc['improvement items']['goals'] != '/' else 'No improvements listed'}\"\n",
    "    # text = (\n",
    "    #     f\"Workstation: {workstation_text}.\\n\n",
    "    #         {ops_text}. \"\n",
    "    #     f\"{doc['improvement items']['goals'] if doc['improvement items']['goals'] != '/' else 'No improvements listed'}.\"\n",
    "\n",
    "    # )\n",
    "    texts.append(text)\n",
    "    doc_ids.append(str(i))\n",
    "    metadatas.append({\n",
    "        \"product_number\": doc[\"product_number\"],\n",
    "        \"workstation_number\": str(doc[\"Workstation number\"]),\n",
    "        \"workstation_name\": doc[\"Workstation name\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1448c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15031ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "print(len(doc_ids))\n",
    "print(len(texts))\n",
    "print(len(metadatas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embed_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "all_embeddings = embed_model.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133efcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "print(len(doc_ids))\n",
    "print(len(metadatas))\n",
    "print(len(texts))\n",
    "\n",
    "print(len(all_embeddings), len(all_embeddings[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dfb67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6368d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b008a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "# Initialize Chroma\n",
    "## Create a collection for data injection\n",
    "\n",
    "# Initialize Chroma\n",
    "collection_name = \"improvement_suggestions\"\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db_6\")\n",
    "\n",
    "try:\n",
    "    collection = chroma_client.create_collection(name=collection_name)\n",
    "    logger.info(f\"Created new collection: {collection_name}\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e).lower():\n",
    "        collection = chroma_client.get_collection(name=collection_name)\n",
    "        logger.info(f\"Collection '{collection_name}' already exists. Using existing collection.\")\n",
    "    else:\n",
    "        logger.error(f\"Failed to create or access collection: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8bcc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_count = collection.count()\n",
    "print(f'Initial count#: {initial_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32e0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma_client.delete_collection(name=collection_name)\n",
    "# collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2fa443",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(ids = doc_ids, embeddings=all_embeddings, documents=texts, metadatas=metadatas)\n",
    "final_count = collection.count()\n",
    "print(f'Final count#: {final_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2bac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text back to the JSON format to make the LLM life easy\n",
    "\n",
    "def structure_document(text: str) -> str:\n",
    "    \"\"\"Convert comma-separated document to JSON.\"\"\"\n",
    "    fields = {}\n",
    "    pairs = text.split(\", \")\n",
    "    for pair in pairs:\n",
    "        if \":\" in pair:\n",
    "            key, value = pair.split(\": \", 1)\n",
    "            fields[key.strip()] = value.strip()\n",
    "    return json.dumps(fields)\n",
    "\n",
    "# During ingestion\n",
    "structured_texts = [structure_document(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(ids = doc_ids, embeddings=all_embeddings, documents=texts, metadatas=metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e87127",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 8\n",
    "print(doc_ids[index])\n",
    "texts[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d2c01",
   "metadata": {},
   "source": [
    "RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d41d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GROK Suggestions\n",
    "import logging\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "def validate_collection_inputs(ids, embeddings, documents, metadatas):\n",
    "    if not all([ids, embeddings, documents]):  # Check for empty inputs\n",
    "        raise ValueError(\"IDs, embeddings, and documents must not be empty\")\n",
    "    if len(ids) != len(embeddings) or len(ids) != len(documents):\n",
    "        raise ValueError(\"IDs, embeddings, and documents must have the same length\")\n",
    "    if metadatas and len(metadatas) != len(ids):\n",
    "        raise ValueError(\"Metadatas length must match IDs length if provided\")\n",
    "\n",
    "try:\n",
    "    validate_collection_inputs(doc_ids, all_embeddings, texts, metadatas)\n",
    "    collection.add(ids=doc_ids, embeddings=all_embeddings, documents=texts, metadatas=metadatas)\n",
    "    logger.info(\"Successfully added data to collection\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to add data to collection: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15da141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template =\"\"\"You will recieve the user's question along with the search results of that question \\\n",
    "over a database. Give the user the proper answer.\n",
    "User's question: {query_texts} \n",
    "Search results: {results}\n",
    "When a question is involved regarding an operation, please fully mention that in your answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555de73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an expert Industrial Engineering Agent designed to provide accurate, detailed, and practical answers to questions in the field of \\\n",
    "    Industrial Engineering. Please provide the answer based on user query and search results.\n",
    "\n",
    "**Input:**\n",
    "- User's question: {query_texts}\n",
    "- Search results: {results}\n",
    "\n",
    "**Instructions:**\n",
    "1. For operations-related questions, include:\n",
    "   - A definition of the operation.\n",
    "   - The steps or components involved.\n",
    "   - Its application or significance in an Industrial Engineering context.\n",
    "2. If applicable, suggest practical tools, techniques, or methodologies (e.g., Lean, Six Sigma, simulation software) to address the question.\n",
    "3. If clarification is needed, politely ask the user for additional details to refine the response.\n",
    "4. If improvement suggestions relevant questions are asked, please answer them in terms of Eliminate, Combine, Rearrange, and Simpify (ECRS) at operation level, include:\n",
    "    - please mention potential benefit quantitatively \n",
    "    - While refering an operation please outline it's full name os user knows which operation you're talking about.\n",
    "    - and also the challenges to implement them.\n",
    "\n",
    "**Output:**\n",
    "A well-structured answer addressing the user's question, grounded in Industrial Engineering principles, with clear explanations of any operations involved.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd427d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import chromadb\n",
    "# # Initialize Chroma\n",
    "# ## Create a collection for data injection\n",
    "# collection_name = \"improvement_suggestions\"\n",
    "# chroma_client = chromadb.PersistentClient(path=\"./chroma_db_5\")\n",
    "\n",
    "# try:\n",
    "#     collection = chroma_client.create_collection(name=collection_name)\n",
    "# except Exception as e:\n",
    "#     if \"already exists\" in str(e):\n",
    "#         # If the collection already exists, use the existing one\n",
    "#         collection = chroma_client.get_collection(name=collection_name)\n",
    "#         print(f\"Collection '{collection_name}' already exists. Using the existing collection.\")\n",
    "#     else:\n",
    "#         # Handle other exceptions\n",
    "#         raise e\n",
    "\n",
    "\n",
    "# collection.add(ids = doc_ids, embeddings=all_embeddings, documents=texts, metadatas=metadatas)\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import textwrap\n",
    "llm = ChatOpenAI(temperature = 0, model = \"gpt-4o\",)\n",
    "\n",
    "\n",
    "# template =\"\"\"You will recieve the user's question along with the search results of that question \\\n",
    "# over a database. Give the user the proper answer.\n",
    "# User's question: {query_texts} \n",
    "# Search results: {results}\n",
    "# When a question is involved regarding an operation, please fully mention that in your answer.\n",
    "# \"\"\"\n",
    "prompt = PromptTemplate.from_template(template=template)\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "The workstations of this production line are:\n",
    "1. Solder ring assembly & press-in (Workstation Number: 10)\n",
    "2. Long and short PIN test (Workstation Number: 15)\n",
    "3. Full inspection & TR packaging (Workstation Number: 17)\n",
    "4. Coplanarity test 1 (Workstation Number: 12)\n",
    "5. 0/S Test (Workstation Number: 8)\n",
    "6. Internal GAP inspection (CCD inspection) (Workstation Number: 13)\n",
    "7. Hi-pottest&Position detection (Workstation Number: 9)\n",
    "8. Coplanarity test (retest) (Workstation Number: 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60401ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_texts = \"Please analyze the workstation 'Coplanarity test (retest)' and provide improvement suggestions?\"\n",
    "query_embeddings = embed_model.embed_query(query_texts)\n",
    "# Load the chromadb collection for vector search\n",
    "vectordb = chroma_client.get_collection(name=\"improvement_suggestions\")\n",
    "# Retrieve relevant chunk\n",
    "results = vectordb.query(\n",
    "    query_embeddings = query_embeddings,\n",
    "    # n_results=1 #top_k\n",
    ")\n",
    "response = chain.invoke({'query_texts': query_texts, 'results': results})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c98a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "wrapped_text = textwrap.wrap(response[:200], width=100)\n",
    "wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d481e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in results.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb40389",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(structured_texts[0])\n",
    "len(structured_texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_texts[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lparser",
   "language": "python",
   "name": "lparser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
