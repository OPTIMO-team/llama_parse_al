{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse the Form Filing File\n",
    "def parse_file(file_path: str) -> List[Document]:\n",
    "    llama_parse = LlamaParse(\n",
    "        api_key=os.environ['LLAMA_CLOUD_API_KEY'],\n",
    "        result_type='markdown',\n",
    "        target_pages=\"0\"\n",
    "    )\n",
    "    result = llama_parse.load_data(\n",
    "        file_path,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 49b0f4f9-bb8a-441f-9e23-c301d2672e71\n"
     ]
    }
   ],
   "source": [
    "documents = parse_file('data/Report_format_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc length: <class 'list'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(f'Doc length: {type(documents)}')\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc length: 1\n",
      "|Items to be improved|Description|Improvement Parameters| | | | | | | | |\n",
      "|---|---|---|---|---|---|---|---|---|---|---|\n",
      "| | |Improvement direction|Person responsible|Expected start date|Actual start date|Expected completion date|Actual completion date|Improve immediately|Confirmation|appendix|\n",
      "|The saturation of the lower glass point Xiaoli Pill is 65%|Low job saturation(lower than95%)| | | | | | | | | |\n",
      "|Bottom glass electrophoresis tank+UVFixed baking operation saturation79.2%|Low job saturation(lower than95%)| | | | | | | | | |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Doc length: {len(documents)}')\n",
    "print(documents[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = documents[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Structured Extraction\n",
    "prompt = f\"\"\"\n",
    "You are an AI assistant specializing in Industrial Engineering problem solving. You've been given an Excel spreadsheet containing items to be improved. \\ \n",
    "and improvement parameters. Your task is to extract and structure this information in a clear, organized format.\n",
    "\n",
    "The Excel sheet contains the following:\n",
    "1. Items to be improved (rows)\n",
    "2. Description (columns)\n",
    "3. Improvement parameters and dates (columns)\n",
    "\n",
    "Input Excel data:\n",
    "{text}\n",
    "\n",
    "Please present the extracted and structured information in a clear, easy-to-read format.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportParameters(BaseModel):\n",
    "    \"\"\"Data model for IE problem solving analysis.\"\"\"\n",
    "    ItemsToBeImproved: List[str]\n",
    "    Description: List[str]\n",
    "    ImprovementParameters: List[str]\n",
    "    # ImprovementPerson: List[str]\n",
    "    # StartDate: List[str]\n",
    "    # CompletionDate: List[str]\n",
    "    # ImproveImmediately: List[bool]\n",
    "    # Confirmation: List[str]\n",
    "    # Appendix: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iâ€™m called ChatGPT. How can I assist you today?'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "llm = OpenAI(model='gpt-4o-mini')\n",
    "input_msg = ChatMessage.from_str('What is your name?')\n",
    "output = llm.chat([input_msg])\n",
    "output.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "sllm = llm.as_structured_llm(output_cls=ReportParameters)\n",
    "input_msg = ChatMessage.from_str(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReportParameters(ItemsToBeImproved=['The saturation of the lower glass point Xiaoli Pill is 65%', 'Bottom glass electrophoresis tank+UVFixed baking operation saturation79.2%'], Description=['Low job saturation(lower than95%)', 'Low job saturation(lower than95%)'], ImprovementParameters=['Improvement direction', 'Person responsible', 'Expected start date', 'Actual start date', 'Expected completion date', 'Actual completion date', 'Improve immediately', 'Confirmation', 'appendix'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = sllm.chat([input_msg])\n",
    "output_obj = output.raw\n",
    "output_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_obj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#print out the items based on the data model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43moutput_obj\u001b[49m\u001b[38;5;241m.\u001b[39mItemsToBeImproved))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output_obj\u001b[38;5;241m.\u001b[39mDescription))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output_obj\u001b[38;5;241m.\u001b[39mImprovementParameters))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_obj' is not defined"
     ]
    }
   ],
   "source": [
    "#print out the items based on the data model\n",
    "print(len(output_obj.ItemsToBeImproved))\n",
    "print(len(output_obj.Description))\n",
    "print(len(output_obj.ImprovementParameters))\n",
    "output_obj.ImprovementParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ItemsToBeImproved = output_obj.ItemsToBeImproved\n",
    "Description = output_obj.Description\n",
    "ImprovementParameters = output_obj.ImprovementParameters[1:]\n",
    "# print(output_obj.ImprovementDirection)\n",
    "# print(output_obj.BriefDescription)\n",
    "# print(output_obj.ImprovementPerson)\n",
    "# print(output_obj.StartDate)\n",
    "# print(output_obj.CompletionDate)\n",
    "# print(output_obj.ImproveImmediately)\n",
    "# print(output_obj.Confirmation)\n",
    "# print(output_obj.Appendix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Person responsible',\n",
       " 'Expected start date',\n",
       " 'Actual start date',\n",
       " 'Expected completion date',\n",
       " 'Actual completion date',\n",
       " 'Improve immediately',\n",
       " 'Confirmation',\n",
       " 'appendix']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ItemsToBeImproved\n",
    "Description\n",
    "ImprovementParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.managed.llama_cloud import LlamaCloudIndex\n",
    "# pip install llama-index-indices-managed-llama-cloud\n",
    "index = LlamaCloudIndex(\n",
    "  name=\"objective-wildfowl-2024-11-24\", \n",
    "  project_name=\"Default\",\n",
    "  organization_id=\"2033a7fc-187e-48e4-a172-5079c4ee2bbf\",\n",
    "  api_key=os.environ['LLAMA_CLOUD_API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    dense_similarity_top_k=10,\n",
    "    sparse_similarity_top_k=10,\n",
    "    alpha=0.5,\n",
    "    enable_reranking=True,\n",
    "    rerank_top_n=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(output_obj.ItemsToBeImproved)\n",
    "# print(output_obj.BriefDescription)\n",
    "# print(output_obj.ImprovementDirection)\n",
    "# print(output_obj.ImprovementPerson)\n",
    "# print(output_obj.StartDate)\n",
    "# print(output_obj.CompletionDate)\n",
    "# print(output_obj.ImproveImmediately)\n",
    "# print(output_obj.Confirmation)\n",
    "# print(output_obj.Appendix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The saturation of the lower glass point Xiaoli Pill is 65%',\n",
       " 'Bottom glass electrophoresis tank+UVFixed baking operation saturation79.2%']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ItemsToBeImproved = output_obj.ItemsToBeImproved\n",
    "# BriefDescription = output_obj.BriefDescription\n",
    "# ImprovementDirection = output_obj.ImprovementDirection\n",
    "# ImprovementPerson = output_obj.ImprovementPerson\n",
    "# StartDate = output_obj.StartDate\n",
    "# CompletionDate = output_obj.CompletionDate\n",
    "# ImproveImmediately = output_obj.ImproveImmediately\n",
    "# Confirmation = output_obj.Confirmation\n",
    "# Appendix = output_obj.Appendix\n",
    "ItemsToBeImproved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['The saturation of the lower glass point Xiaoli Pill is 65%',\n",
    " 'Bottom glass electrophoresis tank+UVFixed baking operation saturation79.2%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sllm.chat(['What is your name?'])\n",
    "Description = ['Low job saturation(higher than95%)',\n",
    " 'Low job saturation(higher than99%)',\n",
    " 'Low job saturation(lower than90%)']\n",
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sllm.chat(['What is your name?'])\n",
    "Description = ['Low job saturation(higher than95%)',\n",
    " 'Low job saturation(higher than99%)',\n",
    " 'Low job saturation(lower than90%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate query and test if it generating them correctly\n",
    "from tqdm import tqdm\n",
    "items_to_be_improved = {}\n",
    "\n",
    "for index, item in enumerate(ItemsToBeImproved[:3]):\n",
    "    text_info = Description[index]\n",
    "    job_saturation = (\n",
    "    f\"Analyze the following text and determine whether the job saturation value mentioned is lower than 95%.\\n\\n\"\n",
    "    f\"Text: \\\"{text_info}\\\"\\n\\n\"\n",
    "    f\"If a job saturation value is explicitly mentioned, check if it is lower than 95%. If so, respond with 'YES'. \"\n",
    "    f\"If it is 95% or higher, respond with 'NO'. If no job saturation value is mentioned, respond with 'NO INFORMATION'.\"\n",
    ")\n",
    "    input_msg = ChatMessage.from_str(job_saturation)\n",
    "    output = llm.chat([input_msg])\n",
    "    answer = output.message.content\n",
    "    \n",
    "    print(index,',',text_info,',',answer)\n",
    "    \n",
    "    # for (index, parameter) in enumerate(ImprovementParameters):\n",
    "    #     des = Description[index]\n",
    "    #     job_saturation = f\"Is the job saturation value lower than 95% for:'{des}'? Your response should be boolean. Either YES or NO?\"\n",
    "    #     # query = f\"What is the '{parameter}' for '{item}'? If you don't know the answer then say 'NA'\"\n",
    "    #     answer = str(query_engine.query(job_saturation))\n",
    "    #     # items_to_be_improved[item][parameter] = answer\n",
    "    #     print(des,',',answer)\n",
    "    #     index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ItemsToBeImproved: List[str]\n",
    "    Description: List[str]\n",
    "    ImprovementParameters: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Item one', 'Item two'] ['one des', 'two des'] ['Improvement direction', 'Person responsible', 'Expected start date', 'Actual start date', 'Expected completion date', 'Actual completion date', 'Improve immediately', 'Confirmation', 'appendix']\n"
     ]
    }
   ],
   "source": [
    "# Your data\n",
    "data_by_row = [\n",
    "    {\n",
    "        'Items to be improved': 'Item one',\n",
    "        'Description': 'one des',\n",
    "        'Improvement direction': '',\n",
    "        'Person responsible': '',\n",
    "        'Expected start date': '',\n",
    "        'Actual start date': '',\n",
    "        'Expected completion date': '',\n",
    "        'Actual completion date': '',\n",
    "        'Improve immediately': '',\n",
    "        'Confirmation': '',\n",
    "        'appendix': ''\n",
    "    },\n",
    "    {\n",
    "        'Items to be improved': 'Item two',\n",
    "        'Description': 'two des',\n",
    "        'Improvement direction': None,\n",
    "        'Person responsible': None,\n",
    "        'Expected start date': None,\n",
    "        'Actual start date': None,\n",
    "        'Expected completion date': None,\n",
    "        'Actual completion date': None,\n",
    "        'Improve immediately': None,\n",
    "        'Confirmation': None,\n",
    "        'appendix': None\n",
    "    }\n",
    "]\n",
    "# Extract 'Items to be improved' as a list\n",
    "ItemsToBeImproved = [entry['Items to be improved'] for entry in data_by_row]\n",
    "Description = [entry['Description'] for entry in data_by_row]\n",
    "ImprovementParameters = list(data_by_row[0].keys())[2:]\n",
    "# new_improvement_directions = generate_answers(ItemsToBeImproved, Description, ImprovementParameters)\n",
    "print(ItemsToBeImproved, Description, ImprovementParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Item one', 'Item two'] ['one des', 'two des'] ['Improvement direction']\n"
     ]
    }
   ],
   "source": [
    "def input_to_ai(data_by_row):\n",
    "    ItemsToBeImproved = [entry['Items to be improved'] for entry in data_by_row]\n",
    "    Description = [entry['Description'] for entry in data_by_row]\n",
    "    ImprovementParameters = [list(data_by_row[0].keys())[2]]\n",
    "    return ItemsToBeImproved, Description, ImprovementParameters\n",
    "ItemsToBeImproved, Description, ImprovementParameters = input_to_ai(data_by_row)\n",
    "print(ItemsToBeImproved, Description, ImprovementParameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Improvement direction']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImprovementParameters = [list(data_by_row[0].keys())[2]]\n",
    "ImprovementParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Items to be improved': 'Item one',\n",
       "  'Description': 'one des',\n",
       "  'Improvement direction': 'New Direction 1',\n",
       "  'Person responsible': '',\n",
       "  'Expected start date': '',\n",
       "  'Actual start date': '',\n",
       "  'Expected completion date': '',\n",
       "  'Actual completion date': '',\n",
       "  'Improve immediately': '',\n",
       "  'Confirmation': '',\n",
       "  'appendix': ''},\n",
       " {'Items to be improved': 'Item two',\n",
       "  'Description': 'two des',\n",
       "  'Improvement direction': 'New Direction 2',\n",
       "  'Person responsible': None,\n",
       "  'Expected start date': None,\n",
       "  'Actual start date': None,\n",
       "  'Expected completion date': None,\n",
       "  'Actual completion date': None,\n",
       "  'Improve immediately': None,\n",
       "  'Confirmation': None,\n",
       "  'appendix': None}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_report_output_content(data_by_row, report_file_name: str, ai_responses: List[str]) -> List[dict]:\n",
    "    # Update the dictionaries\n",
    "    for i, entry in enumerate(data_by_row):\n",
    "        if i < len(ai_responses):\n",
    "            entry['Improvement direction'] = ai_responses[i]\n",
    "    return data_by_row\n",
    "\n",
    "dhon = create_report_output_content(data_by_row, report_file_name: str, ai_responses: List[str]) -> List[dict]:\n",
    "dhon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_info = 'My country name is Bangladsh. I do not know the value of job saturation at this point of time!'\n",
    "# text_info = 'low job saturation (lower than 99%)'\n",
    "# text_info = 'Simultaneous working time of man and machine = manual time (39S) + automatic time (2S) - process standard C/T (41S) = 0S Time of man waiting for machine = automatic time (2S) - simultaneous working time of man and machine (0S)'\n",
    "job_saturation = (\n",
    "    f\"Analyze the following text and determine whether the job saturation value mentioned is lower than 95%.\\n\\n\"\n",
    "    f\"Text: \\\"{text_info}\\\"\\n\\n\"\n",
    "    f\"If a job saturation value is explicitly mentioned, check if it is lower than 95%. If so, respond with 'YES'. \"\n",
    "    f\"If it is 95% or higher, respond with 'NO'. If no job saturation value is mentioned, respond with 'NO INFORMATION'.\"\n",
    ")\n",
    "input_msg = ChatMessage.from_str(job_saturation)\n",
    "output = llm.chat([input_msg])\n",
    "answer = output.message.content\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The saturation of the lower glass point Xiaoli Pill is 65%': {'country': 'india', 'game': 'cricket'}, 'Bottom glass electrophoresis tank+UVFixed baking operation saturation79.2%': {'country': 'pakistan', 'game': 'football'}}\n"
     ]
    }
   ],
   "source": [
    "parameter = ['india', 'pakistan', 'bangaldesh']\n",
    "game = ['cricket', 'football', 'bangaldesh']\n",
    "items_to_be_improved = {}\n",
    "for index, item in enumerate(ItemsToBeImproved):\n",
    "    items_to_be_improved[item] = {}\n",
    "    for country in parameter:\n",
    "        items_to_be_improved[item]['country'] = parameter[index]\n",
    "        items_to_be_improved[item]['game'] = game[index]\n",
    "print(items_to_be_improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Param_1', 'Param_2', 'Param_3']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImprovementParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ItemsToBeImproved):\n\u001b[0;32m      5\u001b[0m     items_to_be_improved[item] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m parameter \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mImprovementParameters\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      7\u001b[0m         query \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      8\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor the problem \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, provide a detailed and concise value or description for the improvement parameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparameter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf the parameter is not applicable or no information is available, respond explicitly with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNA\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsure your response is clear, contextually relevant, and avoids ambiguity.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m             )\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;66;03m# answer = str(query_engine.query(query))\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;66;03m# answer = str(query_engine.query(query))\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "# ItemsToBeImproved: List[str], Description,ImprovementParameters: List[str]) -> List[str]:\n",
    "items_to_be_improved = {}\n",
    "for index, item in enumerate(ItemsToBeImproved):\n",
    "    items_to_be_improved[item] = {}\n",
    "    for parameter in tqdm(ImprovementParameters):\n",
    "        query = (\n",
    "            f\"For the problem '{item}', provide a detailed and concise value or description for the improvement parameter '{parameter}'.\\n\"\n",
    "            f\"If the parameter is not applicable or no information is available, respond explicitly with 'NA'.\\n\\n\"\n",
    "            f\"Ensure your response is clear, contextually relevant, and avoids ambiguity.\"\n",
    "            )\n",
    "        # answer = str(query_engine.query(query))\n",
    "        # answer = str(query_engine.query(query))\n",
    "        items_to_be_improved[item]['Description'] = Description[index]\n",
    "        items_to_be_improved[item][parameter] = '1'\n",
    "items_to_be_improved        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_saturation = (\n",
    "    f\"Analyze the following text and determine whether the job saturation value mentioned is lower than 95%.\\n\\n\"\n",
    "    f\"Text: \\\"{text_info}\\\"\\n\\n\"\n",
    "    f\"If a job saturation value is explicitly mentioned, check if it is lower than 95%. If so, respond with 'YES'. \"\n",
    "    f\"If it is 95% or higher, respond with 'NO'. If no job saturation value is mentioned, respond with 'NO INFORMATION'.\"\n",
    ")\n",
    "input_msg = ChatMessage.from_str(job_saturation)\n",
    "output = llm.chat([input_msg])\n",
    "answer = output.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Description = ['Low job saturation(higher than95%)',\n",
    " 'Low job saturation(lower than95%)',\n",
    " 'Low job saturation(lower than95%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[{'Items to be improved': 'Item one', 'Description': 'one des', 'Improvement direction': '', 'Person responsible': '', \n",
    "  'Expected start date': '', 'Actual start date': '', 'Expected completion date': '', 'Actual completion date': '', \n",
    "  'Improve immediately': '', 'Confirmation': '', 'appendix': ''}, \n",
    "  {'Items to be improved': 'Item two', 'Description': 'two des', 'Improvement direction': None, 'Person responsible': None, 'Expected start date': None, 'Actual start date': None, 'Expected completion date': None, 'Actual completion date': None, 'Improve immediately': None, 'Confirmation': None, 'appendix': None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def generate_answers(ItemsToBeImproved: List[str], Description: List[str], ImprovementParameters: List[str]) -> List[str]:\n",
    "    items_to_be_improved = {}\n",
    "    for index, item in enumerate(ItemsToBeImproved):\n",
    "        items_to_be_improved[item] = {}\n",
    "        for parameter in tqdm(ImprovementParameters):\n",
    "            job_saturation = (\n",
    "                f\"Analyze the following text and determine whether the job saturation value mentioned is lower than 95%.\\n\\n\"\n",
    "                f\"Text: \\\"{Description[index]}\\\"\\n\\n\"\n",
    "                f\"If a job saturation value is explicitly mentioned, check if it is lower than 95%. If so, respond with 'YES'. \"\n",
    "                f\"If it is 95% or higher, respond with 'NO'. If no job saturation value is mentioned, respond with 'NO INFORMATION'.\"\n",
    "            )\n",
    "            input_msg = ChatMessage.from_str(job_saturation)\n",
    "            output = llm.chat([input_msg])\n",
    "            answer = output.message.content\n",
    "            print(Description[index], answer)\n",
    "            if answer == 'YES':\n",
    "                query = (\n",
    "                    f\"For the problem '{item}', provide a detailed and concise value or description for the improvement parameter '{parameter}'.\\n\"\n",
    "                    f\"If the parameter is not applicable or no information is available, respond explicitly with 'NA'.\\n\\n\"\n",
    "                    f\"Ensure your response is clear, contextually relevant, and avoids ambiguity.\"\n",
    "                    )\n",
    "                answer = str(query_engine.query(query))\n",
    "                items_to_be_improved[item]['Description'] = Description[index]\n",
    "                items_to_be_improved[item][parameter] = answer\n",
    "    return items_to_be_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'honeydew kiwi nectarine grape banana mango fig date'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "word_list = [\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\", \"fig\", \"grape\", \"honeydew\", \"kiwi\", \"lemon\", \"mango\", \"nectarine\"]\n",
    "def get_random_words(word_list, num_words=8):\n",
    "    answer = random.sample(word_list, num_words)\n",
    "    return \" \".join(answer)\n",
    "response_1 = get_random_words(word_list)\n",
    "response_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Item one', 'Item two'] ['one des', 'two des'] ['Improvement direction']\n"
     ]
    }
   ],
   "source": [
    "def input_to_ai(data_by_row):\n",
    "    ItemsToBeImproved = [entry['Items to be improved'] for entry in data_by_row]\n",
    "    Description = [entry['Description'] for entry in data_by_row]\n",
    "    ImprovementParameters = [list(data_by_row[0].keys())[2]]\n",
    "    return ItemsToBeImproved, Description, ImprovementParameters\n",
    "ItemsToBeImproved, Description, ImprovementParameters = input_to_ai(data_by_row)\n",
    "print(ItemsToBeImproved, Description, ImprovementParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "ItemsToBeImproved = ['Item_One', 'Item_Two']\n",
    "Description = ['Des_1', 'Des_2']\n",
    "ImprovementParameters = ['Param_1', 'Param_2']\n",
    "\n",
    "def generate_answers(ItemsToBeImproved: List[str], Description: List[str], ImprovementParameters: List[str]) -> List[str]:\n",
    "    for index, item in enumerate(ItemsToBeImproved):\n",
    "        \n",
    "        for parameter in ImprovementParameters:\n",
    "            # job_saturation = (\n",
    "            #     f\"Analyze the following text and determine whether the job saturation value mentioned is lower than 95%.\\n\\n\"\n",
    "            #     f\"Text: \\\"{Description[index]}\\\"\\n\\n\"\n",
    "            #     f\"If a job saturation value is explicitly mentioned, check if it is lower than 95%. If so, respond with 'YES'. \"\n",
    "            #     f\"If it is 95% or higher, respond with 'NO'. If no job saturation value is mentioned, respond with 'NO INFORMATION'.\"\n",
    "            # )\n",
    "            # input_msg = ChatMessage.from_str(job_saturation)\n",
    "            # output = llm.chat([input_msg])\n",
    "            answer = get_random_words(word_list)\n",
    "            responses.append((item, Description[index], answer))\n",
    "\n",
    "            # print(Description[index], answer)\n",
    "            # if answer == 'YES':\n",
    "            #     query = (\n",
    "            #         f\"For the problem '{item}', provide a detailed and concise value or description for the improvement parameter '{parameter}'.\\n\"\n",
    "            #         f\"If the parameter is not applicable or no information is available, respond explicitly with 'NA'.\\n\\n\"\n",
    "            #         f\"Ensure your response is clear, contextually relevant, and avoids ambiguity.\"\n",
    "            #         )\n",
    "            #     answer = str(query_engine.query(query))\n",
    "            # items_to_be_improved[item]['Description'] = Description[index]\n",
    "            # items_to_be_improved[item][parameter] = answer[index]\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Item_Two', 'Des_2', 'honeydew fig mango lemon elderberry grape date apple'),\n",
       " ('Item_Two', 'Des_2', 'fig date grape kiwi lemon nectarine mango banana')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = generate_answers(ItemsToBeImproved, Description, ImprovementParameters)\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The saturation of the lower glass point Xiaoli Pill is 65%',\n",
       "  'Low job saturation(lower than95%)',\n",
       "  'Judgment of value and reduce tasks without added value, Inspection of movement quality and human engineering hazards, Automated level inspection, Merge and rearrange new job elements.'),\n",
       " ('Bottom glass electrophoresis tank+UVFixed baking operation saturation79.2%',\n",
       "  'Low job saturation(lower than95%)',\n",
       "  \"The improvement direction for the problem 'Bottom glass electrophoresis tank+UVFixed baking operation saturation79.2%' is to reduce the number of movements, work with both hands at the same time, shorten the distance of movements, and make movements easier; eliminate human engineering hazards.\")]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "ItemsToBeImproved = ['The saturation of the lower glass point Xiaoli Pill is 65%',\n",
    " 'Bottom glass electrophoresis tank+UVFixed baking operation saturation79.2%']\n",
    "\n",
    "Description = ['Low job saturation(lower than95%)',\n",
    " 'Low job saturation(lower than95%)']\n",
    "ImprovementParameters = ['improvement direction']\n",
    "\n",
    "def generate_answers(ItemsToBeImproved: List[str], Description: List[str], ImprovementParameters: List[str]) -> List[str]:\n",
    "    responses = []\n",
    "    for item, des in zip(ItemsToBeImproved, Description):\n",
    "            job_saturation = (\n",
    "                f\"Analyze the following text and determine whether the job saturation value mentioned is lower than 95%.\\n\\n\"\n",
    "                f\"Text: \\\"{des}\\\"\\n\\n\"\n",
    "                f\"If a job saturation value is explicitly mentioned, check if it is lower than 95%. If so, respond with 'YES'. \"\n",
    "                f\"If it is 95% or higher, respond with 'NO'. If no job saturation value is mentioned, respond with 'NO INFORMATION'.\"\n",
    "            )\n",
    "            input_msg = ChatMessage.from_str(job_saturation)\n",
    "            output = llm.chat([input_msg])\n",
    "            con_check = output.message.content\n",
    "            if con_check == 'YES':\n",
    "                for param in ImprovementParameters:\n",
    "                    query = (\n",
    "                    f\"For the problem '{item}', provide a detailed and concise value or description for the improvement parameter '{param}'.\\n\"\n",
    "                    f\"If the parameter is not applicable or no information is available, respond explicitly with 'NA'.\\n\\n\"\n",
    "                    f\"Ensure your response is clear, contextually relevant, and avoids ambiguity.\"\n",
    "                    )\n",
    "                    answer = str(query_engine.query(query))\n",
    "                    responses.append(answer)\n",
    "    return responses\n",
    "responses = generate_answers(ItemsToBeImproved, Description, ImprovementParameters)\n",
    "responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "flat_data = []\n",
    "for parameter, metrics in answers.items():\n",
    "    flat_metrics = flatten_dict(metrics)\n",
    "    flat_data.append(flat_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers = json.loads(\"\"\"\n",
    "# {'The saturation of the lower glass point Xiaoli Pill is 65%': 'Judgment of value and reduce tasks without added value, Inspection of movement quality and human engineering hazards: Reduce the number of movements, work with both hands at the same time, shorten the distance of movements, and make movements easier; eliminate human engineering hazards, Automated level inspection: simple and automated import, Merge and rearrange new job elements.',\n",
    "#  'Bottom glass electrophoresis tank+UVFixed baking operation saturation 79.2%': 'The improvement direction for Bottom glass electrophoresis tank+UVFixed baking operation saturation 79.2% is to reduce tasks without added value, inspect movement quality and human engineering hazards, conduct automated level inspection, and merge and rearrange new job elements.',\n",
    "#  'Xiaoliwan wax+Paste conductive foam+Lower glass glue frame dispensing operation saturation75%': 'The improvement direction for Xiaoliwan wax+Paste conductive foam+Lower glass glue frame dispensing operation saturation75% is to reduce the number of movements, work with both hands at the same time, shorten the distance of movements, and make movements easier; eliminate human engineering hazards.'}\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Flatten the nested dictionary\n",
    "flat_data = []\n",
    "for parameter, metrics in answers.items():\n",
    "    flat_metrics = flatten_dict(metrics)\n",
    "    flat_metrics['Items to be improved'] = parameter \n",
    "    flat_data.append(flat_metrics)\n",
    "\n",
    "# Get all unique keys to use as CSV headers\n",
    "headers = set()\n",
    "for item in flat_data:\n",
    "    headers.update(item.keys())\n",
    "\n",
    "# Sort headers to ensure 'Items to be improved' comes first\n",
    "headers = sorted(headers)\n",
    "headers.insert(0, headers.pop(headers.index('Items to be improved')))\n",
    "headers.insert(1, headers.pop(headers.index('Description')))\n",
    "headers.insert(2, headers.pop(headers.index('Improvement direction')))\n",
    "headers.insert(3, headers.pop(headers.index('Person responsible')))\n",
    "headers.insert(4, headers.pop(headers.index('Expected start date')))\n",
    "headers.insert(5, headers.pop(headers.index('Actual start date')))\n",
    "headers.insert(6, headers.pop(headers.index('Expected completion date')))\n",
    "headers.insert(7, headers.pop(headers.index('Actual completion date')))\n",
    "headers.insert(8, headers.pop(headers.index('Improve immediately')))\n",
    "headers.insert(9, headers.pop(headers.index('Confirmation')))\n",
    "headers.insert(10, headers.pop(headers.index('appendix')))\n",
    "\n",
    "# Write to CSV\n",
    "with open('Report_format_2_complete.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for row in flat_data:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display import HTML\n",
    "pd.set_option('display.max_colwidth', 10)\n",
    "out_df = pd.read_csv(\"Report_format_2_complete.csv\")\n",
    "html = out_df.to_html()\n",
    "HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_excel(\"Report_format_2_complete.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new duration column for plotting the Gantt Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "file_path = '../llama_parse_al/Report_format_2_complete.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration'] = pd.to_datetime(df['Actual completion date']) - pd.to_datetime(df['Actual start date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position a column to a specified place in pandas\n",
    "columns = list(df.columns)\n",
    "columns.remove('duration')\n",
    "insert_at = columns.index('Actual completion date') + 1\n",
    "columns.insert(insert_at, 'duration')\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the excel file after formatting is done\n",
    "df.to_excel('Report_format_2_complete_input.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_path = '../llama_parse_al/Report_format_2_complete_input.xlsx'\n",
    "os.path.exists(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "from openpyxl.chart.label import DataLabelList\n",
    "# Step 1: Load the Excel file\n",
    "# file_path = \"data.xlsx\"  # Replace with your Excel file path\n",
    "workbook = load_workbook(file_path)\n",
    "sheet = workbook.active  # Use the active sheet (or specify by name: workbook['SheetName'])\n",
    "\n",
    "# Step 2: Identify the data range (e.g., A1:B5)\n",
    "# Assuming the first column has categories (e.g., tasks) and the second has values (e.g., counts)\n",
    "categories = Reference(sheet, min_col=1, min_row=2, max_row=sheet.max_row)  # Task names\n",
    "values = Reference(sheet, min_col=9, min_row=1, max_row=sheet.max_row)  # Values including header\n",
    "\n",
    "# Step 3: Create a horizontal bar chart\n",
    "chart = BarChart()\n",
    "chart.type = \"bar\"  # Horizontal bar chart\n",
    "chart.title = \"Timeline Chart\"\n",
    "chart.y_axis.title = \"Days\"\n",
    "chart.x_axis.title = \"Tasks\"\n",
    "# Add data and categories to the chart\n",
    "chart.add_data(values, titles_from_data=True)\n",
    "chart.set_categories(categories)\n",
    "# Step 5: Add data labels\n",
    "data_labels = DataLabelList()  # Create a DataLabelList object\n",
    "data_labels.showVal = True  # Show values on the bars\n",
    "data_labels.position = 'inBase'\n",
    "chart.dLbls = data_labels\n",
    "chart.legend = None\n",
    "\n",
    "# Step 4: Add the chart to the worksheet\n",
    "sheet.add_chart(chart, \"M2\")  # Place the chart in column D, row 2\n",
    "\n",
    "# Step 5: Save the updated Excel file\n",
    "workbook.save(\"updated_data.xlsx\")\n",
    "print(\"Chart added to 'updated_data.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart.dLbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "workbook = load_workbook(\"Report_format_2_complete.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the active worksheet (or specify the sheet by name)\n",
    "sheet = workbook.active  # or workbook[\"SheetName\"]\n",
    "\n",
    "# Insert a new row at the beginning\n",
    "sheet.insert_rows(1)  # Insert an empty row at the top\n",
    "\n",
    "# Merge two cells (e.g., A1 and B1)\n",
    "sheet.merge_cells(\"E1:F1\")\n",
    "\n",
    "# Write data into the merged cells\n",
    "sheet[\"E1\"] = \"Date\"\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save(\"example.xlsx\")\n",
    "\n",
    "print(\"New row added at the beginning!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gantt chart with custom x-axis embedded in tasks_with_custom_xaxis.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Try improving the graph to make an interactive Gantt Chart\n",
    "## Final version of the graph of Gantt Chart\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "\n",
    "# Step 1: Read Excel file\n",
    "file_path = './data/tasks.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Step 2: Ensure columns are in the correct format\n",
    "df['Start'] = pd.to_datetime(df['Start'])\n",
    "df['Finish'] = pd.to_datetime(df['Finish'])\n",
    "\n",
    "# Step 3: Add a column for data labels (e.g., Task names or durations)\n",
    "df['Label'] =  (df['Finish'] - df['Start']).dt.days.astype(str)\n",
    "# df['Label'] = df['Task'] + \" (\" + ((df['Finish'] - df['Start']).dt.days.astype(str)) + \" days)\"\n",
    "\n",
    "# Step 4: Create a Gantt chart with data labels\n",
    "fig = px.timeline(\n",
    "    df,\n",
    "    x_start=\"Start\",\n",
    "    x_end=\"Finish\",\n",
    "    y=\"Task\",\n",
    "    color=\"Resource\",\n",
    "    text=\"Label\",  # Overlay Task names and durations\n",
    "    title=\"Gantt Chart with Custom X-Axis\"\n",
    ")\n",
    "\n",
    "# Step 5: Customize the x-axis\n",
    "fig.update_traces(textposition=\"auto\", textfont=dict(size=12, color=\"white\"))\n",
    "\n",
    "fig.update_yaxes(categoryorder=\"trace\")  # Optional: Sort tasks by total ascending\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Project Timeline (Dates)\",  # Custom x-axis label\n",
    "    title_x=0.5  # Center the chart title\n",
    ")\n",
    "\n",
    "# Step 6: Save the chart as an image\n",
    "image_file = \"gantt_chart_with_custom_xaxis.png\"\n",
    "fig.write_image(image_file)  # Requires kaleido library (install using `pip install kaleido`)\n",
    "\n",
    "# Step 7: Load the Excel file\n",
    "wb = load_workbook(file_path)\n",
    "ws = wb.active  # Use the first sheet (or specify a sheet name)\n",
    "\n",
    "# Step 8: Insert the image into the Excel file\n",
    "img = Image(image_file)\n",
    "img.anchor = \"E2\"  # Position to embed the image (e.g., cell E2)\n",
    "ws.add_image(img)\n",
    "\n",
    "# Step 9: Save the updated Excel file\n",
    "output_file = \"tasks_with_custom_xaxis.xlsx\"\n",
    "wb.save(output_file)\n",
    "\n",
    "print(f\"Gantt chart with custom x-axis embedded in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lparser",
   "language": "python",
   "name": "lparser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
