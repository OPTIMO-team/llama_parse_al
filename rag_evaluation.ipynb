{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bcde4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6474020",
   "metadata": {},
   "outputs": [],
   "source": [
    "uw_info = \"\"\"\n",
    "The University of Washington, founded in 1861 in Seattle, is a public research university\n",
    "with over 45,000 students across three campuses in Seattle, Tacoma, and Bothell.\n",
    "As the flagship institution of the six public universities in Washington state,\n",
    "UW encompasses over 500 buildings and 20 million square feet of space,\n",
    "including one of the largest library systems in the world.\n",
    "\"\"\"\n",
    "\n",
    "wsu_info = \"\"\"\n",
    "Washington State University, commonly known as WSU, founded in 1890, is a public research university in Pullman, Washington.\n",
    "With multiple campuses across the state, it is the state's second largest institution of higher education.\n",
    "WSU is known for its programs in veterinary medicine, agriculture, engineering, architecture, and pharmacy.\n",
    "\"\"\"\n",
    "\n",
    "seattle_info = \"\"\"\n",
    "Seattle, a city on Puget Sound in the Pacific Northwest, is surrounded by water, mountains and evergreen forests, and contains thousands of acres of parkland.\n",
    "It's home to a large tech industry, with Microsoft and Amazon headquartered in its metropolitan area.\n",
    "The futuristic Space Needle, a legacy of the 1962 World's Fair, is its most iconic landmark.\n",
    "\"\"\"\n",
    "\n",
    "starbucks_info = \"\"\"\n",
    "Starbucks Corporation is an American multinational chain of coffeehouses and roastery reserves headquartered in Seattle, Washington.\n",
    "As the world's largest coffeehouse chain, Starbucks is seen to be the main representation of the United States' second wave of coffee culture.\n",
    "\"\"\"\n",
    "\n",
    "newzealand_info = \"\"\"\n",
    "New Zealand is an island country located in the southwestern Pacific Ocean. It comprises two main landmasses—the North Island and the South Island—and over 700 smaller islands.\n",
    "The country is known for its stunning landscapes, ranging from lush forests and mountains to beaches and lakes. New Zealand has a rich cultural heritage, with influences from \n",
    "both the indigenous Māori people and European settlers. The capital city is Wellington, while the largest city is Auckland. New Zealand is also famous for its adventure tourism,\n",
    "including activities like bungee jumping, skiing, and hiking.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab06b7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seattle, a city on Puget Sound in the Pacific Northwest, is surrounded by water, mountains and evergreen forests, and contains thousands of acres of parkland.\n",
      "It's home to a large tech industry, with Microsoft and Amazon headquartered in its metropolitan area.\n",
      "The futuristic Space Needle, a legacy of the 1962 World's Fair, is its most iconic landmark.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(seattle_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a9c710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "embedding_function = OpenAIEmbeddingFunction(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    model_name=\"text-embedding-ada-002\",\n",
    ")\n",
    "\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "vector_store = chroma_client.get_or_create_collection(\n",
    "    name=\"Washington\", embedding_function=embedding_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163d4c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add(\"uw_info\", documents=uw_info)\n",
    "vector_store.add(\"wsu_info\", documents=wsu_info)\n",
    "vector_store.add(\"seattle_info\", documents=seattle_info)\n",
    "vector_store.add(\"starbucks_info\", documents=starbucks_info)\n",
    "vector_store.add(\"newzealand_info\", documents=newzealand_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c180ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf8cb1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from trulens.apps.app import instrument\n",
    "from trulens.core import TruSession\n",
    "\n",
    "session = TruSession()\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87d0e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "oai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7d6ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RAG:\n",
    "    @instrument\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = vector_store.query(query_texts=query, n_results=4)\n",
    "        # Flatten the list of lists into a single list\n",
    "        return [doc for sublist in results[\"documents\"] for doc in sublist]\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        if len(context_str) == 0:\n",
    "            return \"Sorry, I couldn't find an answer to your question.\"\n",
    "\n",
    "        completion = (\n",
    "            oai_client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=0,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"We have provided context information below. \\n\"\n",
    "                        f\"---------------------\\n\"\n",
    "                        f\"{context_str}\"\n",
    "                        f\"\\n---------------------\\n\"\n",
    "                        f\"First, say hello and that you're happy to help. \\n\"\n",
    "                        f\"\\n---------------------\\n\"\n",
    "                        f\"Then, given this information, please answer the question: {query}\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "            .choices[0]\n",
    "            .message.content\n",
    "        )\n",
    "        if completion:\n",
    "            return completion\n",
    "        else:\n",
    "            return \"Did not find an answer.\"\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve(query=query)\n",
    "        completion = self.generate_completion(\n",
    "            query=query, context_str=context_str\n",
    "        )\n",
    "        return completion\n",
    "\n",
    "\n",
    "rag = RAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07a4d140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.app.retrieve.rets[:] .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import Select\n",
    "from trulens.providers.openai import OpenAI\n",
    "\n",
    "provider = OpenAI(model_engine=\"gpt-4.1-mini\")\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "        provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "    )\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .on_output()\n",
    ")\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "    .on_input()\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Context relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(\n",
    "        provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "    )\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve.rets[:])\n",
    "    .aggregate(np.mean)  # choose a different aggregation method if you wish\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a545e482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrumenting <class '__main__.RAG'> for base <class '__main__.RAG'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting generate_completion\n",
      "\tinstrumenting query\n"
     ]
    }
   ],
   "source": [
    "from trulens.apps.app import TruApp\n",
    "\n",
    "tru_rag = TruApp(\n",
    "    rag,\n",
    "    app_name=\"RAG\",\n",
    "    app_version=\"base\",\n",
    "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51adc4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_rag as recording:\n",
    "    rag.query(\n",
    "        \"What wave of coffee culture is Starbucks seen to represent in the United States?\"\n",
    "    )\n",
    "    rag.query(\n",
    "        \"What wave of coffee culture is Starbucks seen to represent in the New Zealand?\"\n",
    "    )\n",
    "    rag.query(\"Does Washington State have Starbucks on campus?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96c51cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RAG</th>\n",
       "      <th>base</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.507925</td>\n",
       "      <td>0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.365966</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Answer Relevance  Context Relevance  Groundedness  \\\n",
       "app_name app_version                                                      \n",
       "RAG      base                 1.000000           0.166667      0.733333   \n",
       "         filtered             0.333333           1.000000      1.000000   \n",
       "\n",
       "                       latency  total_cost  \n",
       "app_name app_version                        \n",
       "RAG      base         1.507925    0.000621  \n",
       "         filtered     2.365966    0.000078  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d69f37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core.guardrails.base import context_filter\n",
    "\n",
    "guardrail_provider = OpenAI(model_engine=\"gpt-4.1-nano\")\n",
    "\n",
    "# note: feedback function used for guardrail must only return a score, not also reasons\n",
    "f_context_relevance_score = Feedback(\n",
    "    guardrail_provider.context_relevance, name=\"Context Relevance\"\n",
    ")\n",
    "\n",
    "\n",
    "class FilteredRAG(RAG):\n",
    "    @instrument\n",
    "    @context_filter(\n",
    "        feedback=f_context_relevance_score,\n",
    "        threshold=0.75,\n",
    "        keyword_for_prompt=\"query\",\n",
    "    )\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = vector_store.query(query_texts=query, n_results=4)\n",
    "        if \"documents\" in results and results[\"documents\"]:\n",
    "            return [doc for sublist in results[\"documents\"] for doc in sublist]\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "\n",
    "filtered_rag = FilteredRAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a7dbc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Al-Amin\\AppData\\Local\\Temp\\ipykernel_57716\\3098305819.py:3: DeprecationWarning: TruCustomApp is being deprecated in the next major version; use TruApp instead.\n",
      "  filtered_tru_rag = TruCustomApp(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrumenting <class '__main__.FilteredRAG'> for base <class '__main__.FilteredRAG'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting generate_completion\n",
      "\tinstrumenting query\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class '__main__.FilteredRAG'> for base <class '__main__.RAG'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting generate_completion\n",
      "\tinstrumenting query\n",
      "\tinstrumenting retrieve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Al-Amin\\llama_parse_al\\env\\lib\\site-packages\\trulens\\core\\feedback\\feedback.py:1023: UserWarning: Feedback function Context Relevance with aggregation <function mean at 0x0000025AAD0619D0> had no inputs.\n",
      "  warnings.warn(\n",
      "D:\\Al-Amin\\llama_parse_al\\env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "D:\\Al-Amin\\llama_parse_al\\env\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from trulens.apps.custom import TruCustomApp\n",
    "\n",
    "filtered_tru_rag = TruCustomApp(\n",
    "    filtered_rag,\n",
    "    app_name=\"RAG\",\n",
    "    app_version=\"filtered\",\n",
    "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
    ")\n",
    "\n",
    "with filtered_tru_rag as recording:\n",
    "    filtered_rag.query(\n",
    "        query=\"What wave of coffee culture is Starbucks seen to represent in the United States?\"\n",
    "    )\n",
    "    filtered_rag.query(\n",
    "        \"What wave of coffee culture is Starbucks seen to represent in the New Zealand?\"\n",
    "    )\n",
    "    filtered_rag.query(\"Does Washington State have Starbucks on campus?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb554cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RAG</th>\n",
       "      <th>base</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.507925</td>\n",
       "      <td>0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filtered</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.200799</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Answer Relevance  Context Relevance  Groundedness  \\\n",
       "app_name app_version                                                      \n",
       "RAG      base                 1.000000           0.166667      0.777778   \n",
       "         filtered             0.333333           1.000000      1.000000   \n",
       "\n",
       "                       latency  total_cost  \n",
       "app_name app_version                        \n",
       "RAG      base         1.507925    0.000621  \n",
       "         filtered     2.200799    0.000078  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41c644d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Dashboard already running at path:   Local URL: http://localhost:56181\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21522b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "530a5eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Groundedness, input source will be set to __record__.app.retrieve.rets.collect() .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.app.retrieve.rets[:] .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import Select\n",
    "from trulens.providers.openai import OpenAI\n",
    "\n",
    "provider = OpenAI(model_engine=\"gpt-4.1-mini\")\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "        provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "    )\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .on_output()\n",
    ")\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = (\n",
    "    Feedback(provider.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "    .on_input()\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Context relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(\n",
    "        provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "    )\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve.rets[:])\n",
    "    .aggregate(np.mean)  # choose a different aggregation method if you wish\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ded4cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrumenting <class '__main__.RAG'> for base <class '__main__.RAG'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting generate_completion\n",
      "\tinstrumenting query\n"
     ]
    }
   ],
   "source": [
    "from trulens.apps.app import TruApp\n",
    "\n",
    "tru_rag = TruApp(\n",
    "    rag,\n",
    "    app_name=\"RAG\",\n",
    "    app_version=\"base\",\n",
    "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1650c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deveoping the app\n",
    "from llama_index.core import ServiceContext, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core import load_index_from_storage\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dc7d0ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sentence_window_index(\n",
    "    document, llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", save_dir=\"sentence_index\"\n",
    "):\n",
    "    # create the sentence window node parser w/ default settings\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=3,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    sentence_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "        node_parser=node_parser,\n",
    "    )\n",
    "    if not os.path.exists(save_dir):\n",
    "        sentence_index = VectorStoreIndex.from_documents(\n",
    "            [document], service_context=sentence_context\n",
    "        )\n",
    "        sentence_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        sentence_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=sentence_context,\n",
    "        )\n",
    "\n",
    "    return sentence_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c16df869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    Settings,\n",
    "    Document\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def build_sentence_window_index(\n",
    "    document: Document,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"sentence_index\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Build or load a sentence window index for a given document.\n",
    "\n",
    "    Args:\n",
    "        document (Document): The input document to index.\n",
    "        llm: The language model to use (e.g., OpenAI).\n",
    "        embed_model (str): The embedding model (default: BAAI/bge-small-en-v1.5).\n",
    "        save_dir (str): Directory to persist the index (default: sentence_index).\n",
    "\n",
    "    Returns:\n",
    "        VectorStoreIndex: The built or loaded sentence window index.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Configure global settings\n",
    "        Settings.llm = llm\n",
    "        Settings.embed_model = embed_model\n",
    "\n",
    "        # Create the sentence window node parser with default settings\n",
    "        node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "            window_size=3,\n",
    "            window_metadata_key=\"window\",\n",
    "            original_text_metadata_key=\"original_text\"\n",
    "        )\n",
    "        Settings.node_parser = node_parser\n",
    "\n",
    "        # Parse document into nodes\n",
    "        nodes = node_parser.get_nodes_from_documents([document])\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            # Build new index\n",
    "            logger.info(f\"Creating new index at {save_dir}\")\n",
    "            sentence_index = VectorStoreIndex(nodes)\n",
    "            sentence_index.storage_context.persist(persist_dir=save_dir)\n",
    "        else:\n",
    "            # Load existing index\n",
    "            logger.info(f\"Loading index from {save_dir}\")\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=save_dir)\n",
    "            sentence_index = load_index_from_storage(storage_context)\n",
    "\n",
    "        return sentence_index\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error building/loading sentence window index: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0dd3dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_window_query_engine(\n",
    "    sentence_index,\n",
    "    similarity_top_k=6,\n",
    "    rerank_top_n=2,\n",
    "):\n",
    "    # define postprocessors\n",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "\n",
    "    sentence_window_engine = sentence_index.as_query_engine(\n",
    "        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank]\n",
    "    )\n",
    "    return sentence_window_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a27cc570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import HierarchicalNodeParser\n",
    "\n",
    "from llama_index.core.node_parser import get_leaf_nodes\n",
    "from llama_index.core.retrievers import AutoMergingRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d3c0a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_automerging_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"merging_index\",\n",
    "    chunk_sizes=None,\n",
    "):\n",
    "    chunk_sizes = chunk_sizes or [2048, 512, 128]\n",
    "    node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=chunk_sizes)\n",
    "    nodes = node_parser.get_nodes_from_documents(documents)\n",
    "    leaf_nodes = get_leaf_nodes(nodes)\n",
    "    merging_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "    )\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "    storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        automerging_index = VectorStoreIndex(\n",
    "            leaf_nodes, storage_context=storage_context, service_context=merging_context\n",
    "        )\n",
    "        automerging_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        automerging_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=merging_context,\n",
    "        )\n",
    "    return automerging_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b85b43df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_automerging_query_engine(\n",
    "    automerging_index,\n",
    "    similarity_top_k=12,\n",
    "    rerank_top_n=2,\n",
    "):\n",
    "    base_retriever = automerging_index.as_retriever(similarity_top_k=similarity_top_k)\n",
    "    retriever = AutoMergingRetriever(\n",
    "        base_retriever, automerging_index.storage_context, verbose=True\n",
    "    )\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "    auto_merging_engine = RetrieverQueryEngine.from_args(\n",
    "        retriever, node_postprocessors=[rerank]\n",
    "    )\n",
    "    return auto_merging_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "199ef001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lesson 2: RAG Triad of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d2bae3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import Document\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "654597ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "92c8cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = Document(text=\"\\n\\n\".\\\n",
    "                    join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b923bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a8567c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "llama_index.core.schema.Document"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(documents))\n",
    "print(len(documents))\n",
    "type(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "44d2cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "OpenAI_Embedding = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4d648d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    Settings,\n",
    "    Document\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def build_sentence_window_index(\n",
    "    document: Document,\n",
    "    llm,\n",
    "    embed_model=OpenAI_Embedding,\n",
    "    save_dir=\"sentence_index\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Build or load a sentence window index for a given document.\n",
    "\n",
    "    Args:\n",
    "        document (Document): The input document to index.\n",
    "        llm: The language model to use (e.g., OpenAI).\n",
    "        embed_model (str): The embedding model (default: BAAI/bge-small-en-v1.5).\n",
    "        save_dir (str): Directory to persist the index (default: sentence_index).\n",
    "\n",
    "    Returns:\n",
    "        VectorStoreIndex: The built or loaded sentence window index.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Configure global settings\n",
    "        Settings.llm = llm\n",
    "        Settings.embed_model = embed_model\n",
    "\n",
    "        # Create the sentence window node parser with default settings\n",
    "        node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "            window_size=3,\n",
    "            window_metadata_key=\"window\",\n",
    "            original_text_metadata_key=\"original_text\"\n",
    "        )\n",
    "        Settings.node_parser = node_parser\n",
    "\n",
    "        # Parse document into nodes\n",
    "        nodes = node_parser.get_nodes_from_documents([document])\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            # Build new index\n",
    "            logger.info(f\"Creating new index at {save_dir}\")\n",
    "            sentence_index = VectorStoreIndex(nodes)\n",
    "            sentence_index.storage_context.persist(persist_dir=save_dir)\n",
    "        else:\n",
    "            # Load existing index\n",
    "            logger.info(f\"Loading index from {save_dir}\")\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=save_dir)\n",
    "            sentence_index = load_index_from_storage(storage_context)\n",
    "\n",
    "        return sentence_index\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error building/loading sentence window index: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0b2e949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index = build_sentence_window_index(\n",
    "    document,\n",
    "    llm,\n",
    "    save_dir=\"sentence_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c63f1d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43aaf5aef524656b27eb3594a6a66d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/799 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Al-Amin\\llama_parse_al\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Al-Amin\\.cache\\huggingface\\hub\\models--BAAI--bge-reranker-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8f0359c722431dbcaaf0bf45f3a3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75e77f97e8a4db4b6979d862ce5c92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4882ce468824342ba5d1d5475d85938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c757004041484f92b357a43288e6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac994c3b1524d939efc79d465853a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_window_engine = \\\n",
    "get_sentence_window_query_engine(sentence_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2e5d223b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You create your AI portfolio by showcasing a progression of projects that demonstrate your skills in AI.'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = sentence_window_engine.query(\n",
    "    \"How do you create your AI portfolio?\")\n",
    "output.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6cfd6b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='You create your AI portfolio by showcasing a progression of projects that demonstrate your skills in AI.', source_nodes=[NodeWithScore(node=TextNode(id_='7c6cdb2c-571f-413e-bf87-e5c21fed67b9', embedding=None, metadata={'window': 'Chapter 4: Scoping Successful AI Projects.\\n Chapter 5: Finding Projects that Complement \\nYour Career Goals.\\n Chapter 6: Building a Portfolio of Projects that \\nShows Skill Progression.\\n Chapter 7: A Simple Framework for Starting Your AI \\nJob Search.\\n Chapter 8: Using Informational Interviews to Find \\nthe Right Job.\\n Chapter 9: Finding the Right AI Job for You.\\n Chapter 10: Keys to Building a Career in AI.\\n', 'original_text': 'Chapter 7: A Simple Framework for Starting Your AI \\nJob Search.\\n'}, excluded_embed_metadata_keys=['window', 'original_text'], excluded_llm_metadata_keys=['window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7b812dd1-3a21-439d-a101-2317c4dee3f0', node_type='4', metadata={}, hash='cce73b104a707c41b62fbb6508a0dbd99fe6d435eaf23073d0dca24f6f55e331'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e39bca00-4e58-4640-b57e-912c1ffa7299', node_type='1', metadata={'window': 'Chapter 3: Should You Learn Math to Get a Job \\nin AI?\\n Chapter 4: Scoping Successful AI Projects.\\n Chapter 5: Finding Projects that Complement \\nYour Career Goals.\\n Chapter 6: Building a Portfolio of Projects that \\nShows Skill Progression.\\n Chapter 7: A Simple Framework for Starting Your AI \\nJob Search.\\n Chapter 8: Using Informational Interviews to Find \\nthe Right Job.\\n Chapter 9: Finding the Right AI Job for You.\\n', 'original_text': 'Chapter 6: Building a Portfolio of Projects that \\nShows Skill Progression.\\n'}, hash='f40784c261ce835ebd7cc44290fae1b415e97539251353013e1a5e40d9d6ab46'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='7866282b-5d10-4094-84ba-7b5c1fab50eb', node_type='1', metadata={'window': 'Chapter 5: Finding Projects that Complement \\nYour Career Goals.\\n Chapter 6: Building a Portfolio of Projects that \\nShows Skill Progression.\\n Chapter 7: A Simple Framework for Starting Your AI \\nJob Search.\\n Chapter 8: Using Informational Interviews to Find \\nthe Right Job.\\n Chapter 9: Finding the Right AI Job for You.\\n Chapter 10: Keys to Building a Career in AI.\\n Chapter 11: Overcoming Imposter Syndrome.\\n', 'original_text': 'Chapter 8: Using Informational Interviews to Find \\nthe Right Job.\\n'}, hash='2afe65518ac61b5ebae3f319bef318a9eee6044aede561627a5e5580ef0ac146')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Chapter 4: Scoping Successful AI Projects.\\n Chapter 5: Finding Projects that Complement \\nYour Career Goals.\\n Chapter 6: Building a Portfolio of Projects that \\nShows Skill Progression.\\n Chapter 7: A Simple Framework for Starting Your AI \\nJob Search.\\n Chapter 8: Using Informational Interviews to Find \\nthe Right Job.\\n Chapter 9: Finding the Right AI Job for You.\\n Chapter 10: Keys to Building a Career in AI.\\n', mimetype='text/plain', start_char_idx=633, end_char_idx=697, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.56008214), NodeWithScore(node=TextNode(id_='8d4170cc-2d1d-49d8-9fdc-3a85b518c8a3', embedding=None, metadata={'window': 'Chapter 6: Building a Portfolio of Projects that \\nShows Skill Progression.\\n Chapter 7: A Simple Framework for Starting Your AI \\nJob Search.\\n Chapter 8: Using Informational Interviews to Find \\nthe Right Job.\\n Chapter 9: Finding the Right AI Job for You.\\n Chapter 10: Keys to Building a Career in AI.\\n Chapter 11: Overcoming Imposter Syndrome.\\n Final Thoughts: Make Every Day Count.\\n', 'original_text': 'Chapter 9: Finding the Right AI Job for You.\\n'}, excluded_embed_metadata_keys=['window', 'original_text'], excluded_llm_metadata_keys=['window', 'original_text'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7b812dd1-3a21-439d-a101-2317c4dee3f0', node_type='4', metadata={}, hash='cce73b104a707c41b62fbb6508a0dbd99fe6d435eaf23073d0dca24f6f55e331'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7866282b-5d10-4094-84ba-7b5c1fab50eb', node_type='1', metadata={'window': 'Chapter 5: Finding Projects that Complement \\nYour Career Goals.\\n Chapter 6: Building a Portfolio of Projects that \\nShows Skill Progression.\\n Chapter 7: A Simple Framework for Starting Your AI \\nJob Search.\\n Chapter 8: Using Informational Interviews to Find \\nthe Right Job.\\n Chapter 9: Finding the Right AI Job for You.\\n Chapter 10: Keys to Building a Career in AI.\\n Chapter 11: Overcoming Imposter Syndrome.\\n', 'original_text': 'Chapter 8: Using Informational Interviews to Find \\nthe Right Job.\\n'}, hash='2afe65518ac61b5ebae3f319bef318a9eee6044aede561627a5e5580ef0ac146'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='967b45b7-520d-478a-8f42-93c995d9369f', node_type='1', metadata={'window': 'Chapter 7: A Simple Framework for Starting Your AI \\nJob Search.\\n Chapter 8: Using Informational Interviews to Find \\nthe Right Job.\\n Chapter 9: Finding the Right AI Job for You.\\n Chapter 10: Keys to Building a Career in AI.\\n Chapter 11: Overcoming Imposter Syndrome.\\n Final Thoughts: Make Every Day Count.\\n LEARNING\\nPROJECTS\\nJOB\\n\\nPAGE 4\\nCoding AI Is the New Literacy\\nToday we take it for granted that many people know how to read and write. ', 'original_text': 'Chapter 10: Keys to Building a Career in AI.\\n'}, hash='70b5452db8acf01e49aeda789009ad95a32e61ff91c9b0d56d69d2ad2441ead1')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Chapter 6: Building a Portfolio of Projects that \\nShows Skill Progression.\\n Chapter 7: A Simple Framework for Starting Your AI \\nJob Search.\\n Chapter 8: Using Informational Interviews to Find \\nthe Right Job.\\n Chapter 9: Finding the Right AI Job for You.\\n Chapter 10: Keys to Building a Career in AI.\\n Chapter 11: Overcoming Imposter Syndrome.\\n Final Thoughts: Make Every Day Count.\\n', mimetype='text/plain', start_char_idx=763, end_char_idx=808, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5557502)], metadata={'7c6cdb2c-571f-413e-bf87-e5c21fed67b9': {'window': 'Chapter 4: Scoping Successful AI Projects.\\n Chapter 5: Finding Projects that Complement \\nYour Career Goals.\\n Chapter 6: Building a Portfolio of Projects that \\nShows Skill Progression.\\n Chapter 7: A Simple Framework for Starting Your AI \\nJob Search.\\n Chapter 8: Using Informational Interviews to Find \\nthe Right Job.\\n Chapter 9: Finding the Right AI Job for You.\\n Chapter 10: Keys to Building a Career in AI.\\n', 'original_text': 'Chapter 7: A Simple Framework for Starting Your AI \\nJob Search.\\n'}, '8d4170cc-2d1d-49d8-9fdc-3a85b518c8a3': {'window': 'Chapter 6: Building a Portfolio of Projects that \\nShows Skill Progression.\\n Chapter 7: A Simple Framework for Starting Your AI \\nJob Search.\\n Chapter 8: Using Informational Interviews to Find \\nthe Right Job.\\n Chapter 9: Finding the Right AI Job for You.\\n Chapter 10: Keys to Building a Career in AI.\\n Chapter 11: Overcoming Imposter Syndrome.\\n Final Thoughts: Make Every Day Count.\\n', 'original_text': 'Chapter 9: Finding the Right AI Job for You.\\n'}})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e0376",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_groundedness, f_answer_relevance, f_context_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5b5b778e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Groundedness, input source will be set to __record__.calls[-1].rets.source_nodes[:].node.text.collect() .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.calls[-1].rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from trulens.apps.llamaindex import TruLlama\n",
    "from trulens.core import Feedback\n",
    "from trulens.providers.openai import OpenAI\n",
    "\n",
    "# Initialize provider class\n",
    "provider = OpenAI(model_engine=\"gpt-4.1-mini\")\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "\n",
    "context = TruLlama.select_context(sentence_window_engine)\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "        provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "    )\n",
    "    .on(context.collect())  # collect context chunks into a list\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = Feedback(\n",
    "    provider.relevance_with_cot_reasons, name=\"Answer Relevance\"\n",
    ").on_input_output()\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(\n",
    "        provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "    )\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e6997a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrumenting <class 'llama_index.embeddings.openai.base.OpenAIEmbedding'> for base <class 'llama_index.embeddings.openai.base.OpenAIEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.openai.base.OpenAIEmbedding'> for base <class 'llama_index.core.base.embeddings.base.BaseEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.openai.base.OpenAIEmbedding'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.openai.base.OpenAIEmbedding'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.openai.base.OpenAIEmbedding'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.embeddings.openai.base.OpenAIEmbedding'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.embeddings.openai.base.OpenAIEmbedding'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.embeddings.openai.base.OpenAIEmbedding'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'llama_index.core.callbacks.base_handler.BaseCallbackHandler'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'object'>\n",
      "instrumenting <class 'tuple'> for base <class 'tuple'>\n",
      "instrumenting <class 'tuple'> for base <class 'object'>\n",
      "instrumenting <class 'pydantic.fields.FieldInfo'> for base <class 'pydantic.fields.FieldInfo'>\n",
      "instrumenting <class 'pydantic.fields.FieldInfo'> for base <class 'pydantic._internal._repr.Representation'>\n",
      "instrumenting <class 'pydantic.fields.FieldInfo'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.types.BasePydanticVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.base.BaseIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'llama_index.core.graph_stores.types.GraphStore'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Protocol'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.node_parser.interface.NodeParser'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence_window.SentenceWindowNodeParser'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.keyval_docstore.KVDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.types.BaseDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'llama_index.core.data_structs.data_structs.IndexStruct'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'llama_index.core.storage.docstore.types.RefDocInfo'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.storage_context.StorageContext'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.base_retriever.BaseRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.llms.openai.base.OpenAI'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.function_calling.FunctionCallingLLM'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.llm.LLM'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.base.llms.base.BaseLLM'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'llama_index.core.base.llms.types.LLMMetadata'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.indices.prompt_helper.PromptHelper'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.refine.Refine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.base.BaseSynthesizer'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.base_query_engine.BaseQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.postprocessor.types.BaseNodePostprocessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.postprocessor.types.BaseNodePostprocessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.base.query_pipeline.query.ChainableMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'object'>\n"
     ]
    }
   ],
   "source": [
    "tru_query_engine_recorder = TruLlama(\n",
    "    sentence_window_engine,\n",
    "    app_name=\"LlamaIndex_App\",\n",
    "    app_version=\"base\",\n",
    "    feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9f6d434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or as context manager\n",
    "with tru_query_engine_recorder as recording:\n",
    "    sentence_window_engine.query(\"What did the author do growing up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dfc56fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Dashboard already running at path:   Local URL: http://localhost:56181\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_dashboard(session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lparser",
   "language": "python",
   "name": "lparser"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
